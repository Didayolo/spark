{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Visual Guide to Spark's API\n",
    "### Time to complete: 30 minutes\n",
    "#### This lab will introduce you to using Apache Spark with the Python API. We will explore common transformations and actions including\n",
    "* Actions: Collect, Count, GetNumPartitions, Reduce, Aggregate, Max, Min, Sum, Mean, Variance, Stdev, CountByKey, SaveAsTextFile, \n",
    "* Transformations + MISC operations: Map, Filter, FlatMap, GroupBy, GroupByKey, MapPartitions, MapPartitionsWithIndex, Sample, Union, Join, Distinct, Coalese, KeyBy, PartitionBy, Zip\n",
    "\n",
    "\n",
    "Note that these images were inspired by Jeff Thomson's 67 \"PySpark images\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect\n",
    "-------\n",
    "\n",
    "Action / To Driver: Return all items in the RDD to the driver in a single list\n",
    "\n",
    "Start with this action, since it is used in all of the examples.\n",
    "\n",
    "![](http://i.imgur.com/DUO6ygB.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1,2,3], 2)\n",
    "y = x.collect()\n",
    "print(x.glom().collect()) # glom() flattens elements on the same partition\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "Create a new RDD from one or more RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map\n",
    "---\n",
    "\n",
    "Transformation / Narrow: Return a new RDD by applying a function to each element of this RDD\n",
    "\n",
    "![](http://i.imgur.com/PxNJf0U.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([\"b\", \"a\", \"c\"])\n",
    "y = x.map(lambda z: (z, 1))\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try it!** change the indicated line to produce squares of the original numbers\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lab exercise:\n",
    "\n",
    "x = sc.parallelize([1,2,3,4])\n",
    "y = x.map(lambda n: n) #CHANGE the lambda to take a number and returns its square\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter\n",
    "\n",
    "Transformation / Narrow: Return a new RDD containing only the elements that satisfy a predicate\n",
    "\n",
    "![](http://i.imgur.com/GFyji4U.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1,2,3])\n",
    "y = x.filter(lambda x: x%2 == 1) #keep odd values \n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####**Try it!** Change the sample to keep even numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lab exercise:\n",
    "x = sc.parallelize([1,2,3])\n",
    "y = x.filter(  ) #add a lambda parameter to keep only even numbers\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FlatMap\n",
    "\n",
    "Transformation / Narrow: Return a new RDD by first applying a function to all elements of this RDD, and then flattening the results\n",
    "\n",
    "![](http://i.imgur.com/TsSUex8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1,2,3])\n",
    "y = x.flatMap(lambda x: (x, x*100, 42))\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy\n",
    "\n",
    "Transformation / Wide: Group the data in the original RDD. Create pairs where the key is the output of a user function, and the value is all items for which the function yields this key.\n",
    "\n",
    "![](http://i.imgur.com/gdj0Ey8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://stackoverflow.com/questions/36798833/what-does-exception-randomness-of-hash-of-string-should-be-disabled-via-pythonh\n",
    "x = sc.parallelize(['John', 'Fred', 'Anna', 'James'])\n",
    "y = x.groupBy(lambda w: w[0])\n",
    "print([(k, list(v)) for (k, v) in y.collect()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupByKey\n",
    "\n",
    "Transformation / Wide: Group the values for each key in the original RDD. Create a new pair where the original key corresponds to this collected group of values.\n",
    "\n",
    "![](http://i.imgur.com/TlWRGr2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([('B',5),('B',4),('A',3),('A',2),('A',1)])\n",
    "y = x.groupByKey()\n",
    "print(x.collect())\n",
    "print(list((j[0], list(j[1])) for j in y.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MapPartitions\n",
    "\n",
    "Transformation / Narrow: Return a new RDD by applying a function to each partition of this RDD\n",
    "\n",
    "![](http://i.imgur.com/dw8QOLX.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1,2,3], 2)\n",
    "\n",
    "def f(iterator): yield sum(iterator); yield 42\n",
    "\n",
    "y = x.mapPartitions(f)\n",
    "\n",
    "print(x.glom().collect())\n",
    "print(y.glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MapPartitionsWithIndex\n",
    "\n",
    "Transformation / Narrow: Return a new RDD by applying a function to each partition of this RDD, while tracking the index of the original partition\n",
    "\n",
    "![](http://i.imgur.com/3cGvAF7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1,2,3], 2)\n",
    "\n",
    "def f(partitionIndex, iterator): yield (partitionIndex, sum(iterator))\n",
    "\n",
    "y = x.mapPartitionsWithIndex(f)\n",
    "\n",
    "print(x.glom().collect())\n",
    "print(y.glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample\n",
    "\n",
    "Transformation / Narrow: Return a new RDD containing a statistical sample of the original RDD\n",
    "\n",
    "![](http://i.imgur.com/LJ56nQq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1, 2, 3, 4, 5])\n",
    "y = x.sample(False, 0.4, 42)\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union\n",
    "\n",
    "Transformation / Narrow: Return a new RDD containing all items from two original RDDs. Duplicates are not culled.\n",
    "\n",
    "![](http://i.imgur.com/XFpbqZ8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1,2,3], 2)\n",
    "y = sc.parallelize([3,4], 1)\n",
    "z = x.union(y)\n",
    "print(z.glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join\n",
    "\n",
    "Transformation / Wide: Return a new RDD containing all pairs of elements having the same key in the original RDDs\n",
    "\n",
    "![](http://i.imgur.com/YXL42Nl.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([(\"a\", 1), (\"b\", 2)])\n",
    "y = sc.parallelize([(\"a\", 3), (\"a\", 4), (\"b\", 5)])\n",
    "z = x.join(y)\n",
    "print(z.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####**Try it!** Join the RDDs so that each company's name and stock price are collected into a tuple value, whose key is the company ticker symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([(\"TWTR\", \"Twitter\"), (\"GOOG\", \"Google\"), (\"AAPL\", \"Apple\")])\n",
    "y = sc.parallelize([(\"TWTR\", 36), (\"GOOG\", 532), (\"AAPL\", 127)])\n",
    "\n",
    "#Add code here to perform a join and print the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinct\n",
    "\n",
    "Transformation / Wide: Return a new RDD containing distinct items from the original RDD (omitting all duplicates)\n",
    "\n",
    "![](http://i.imgur.com/Vqgy2a4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1,2,3,3,4])\n",
    "y = x.distinct()\n",
    "\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coalesce\n",
    "\n",
    "Transformation / Narrow or Wide: Return a new RDD which is reduced to a smaller number of partitions\n",
    "\n",
    "![](http://i.imgur.com/woQiM7E.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1, 2, 3, 4, 5], 3)\n",
    "y = x.coalesce(2)\n",
    "print(x.glom().collect())\n",
    "print(y.glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KeyBy\n",
    "\n",
    "Transformation / Narrow: Create a Pair RDD, forming one pair for each item in the original RDD. The pair’s key is calculated from the value via a user-supplied function.\n",
    "\n",
    "![](http://i.imgur.com/nqYhDW5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize(['John', 'Fred', 'Anna', 'James'])\n",
    "y = x.keyBy(lambda w: w[0])\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####**Try it!** Create an RDD from this list, and then use .keyBy to create a pair RDD where the state abbreviation is the key and the city + state is the value (e.g., (\"NY\", \"New York, NY\")) ... For extra credit, add a .map that strips out the redundant state abbreviation to yield pairs like (\"NY\", \"New York\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [\"New York, NY\", \"Philadelphia, PA\", \"Denver, CO\", \"San Francisco, CA\"]\n",
    "# Add code to parallelize the list to an RDD\n",
    "# call .keyBy on the RDD to create an RDD of pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PartitionBy\n",
    "\n",
    "Transformation / Wide: Return a new RDD with the specified number of partitions, placing original items into the partition returned by a user supplied function\n",
    "\n",
    "![](http://i.imgur.com/QHDWwYv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([('J','James'),('F','Fred'), ('A','Anna'),('J','John')], 3)\n",
    "\n",
    "y = x.partitionBy(2, lambda w: 0 if w[0] < 'H' else 1)\n",
    "\n",
    "print(x.glom().collect())\n",
    "print(y.glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip\n",
    "\n",
    "Transformation / Narrow: Return a new RDD containing pairs whose key is the item in the original RDD, and whose value is that item’s corresponding element (same partition, same index) in a second RDD\n",
    "\n",
    "![](http://i.imgur.com/5J0lg6g.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1, 2, 3])\n",
    "y = x.map(lambda n:n*n)\n",
    "z = x.zip(y)\n",
    "\n",
    "print(z.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions\n",
    "\n",
    "Calculate a result (e.g., numeric data or creata a non-RDD data structure), or produce a side effect, such as writing output to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GetNumPartitions\n",
    "\n",
    "Action / To Driver: Return the number of partitions in RDD\n",
    "\n",
    "![](http://i.imgur.com/9yhDsVX.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1,2,3], 2)\n",
    "y = x.getNumPartitions()\n",
    "\n",
    "print(x.glom().collect())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce\n",
    "\n",
    "Action / To Driver: Aggregate all the elements of the RDD by applying a user function pairwise to elements and partial results, and return a result to the driver\n",
    "\n",
    "![](http://i.imgur.com/R72uzwX.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1,2,3,4])\n",
    "y = x.reduce(lambda a,b: a+b)\n",
    "\n",
    "print(x.collect())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate\n",
    "\n",
    "Action / To Driver: Aggregate all the elements of the RDD by: \n",
    "  - applying a user function to combine elements with user-supplied objects, \n",
    "  - then combining those user-defined results via a second user function, \n",
    "  - and finally returning a result to the driver.\n",
    "  \n",
    "![](http://i.imgur.com/7MLnYeh.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seqOp = lambda data, item: (data[0] + [item], data[1] + item)\n",
    "combOp = lambda d1, d2: (d1[0] + d2[0], d1[1] + d2[1])\n",
    "\n",
    "x = sc.parallelize([1,2,3,4])\n",
    "\n",
    "y = x.aggregate(([], 0), seqOp, combOp)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####**Try it!** Can you use .aggregate to collect the inputs into a plain list -- so that the output of your .aggregate is just like that of .collect? How about producing a plain total, just like .sum? What does that tell you about the amount of data returned from .aggregate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([1,2,3,4])\n",
    "\n",
    "#define appropriate seqOp and combOp\n",
    "seqOp = lambda #...\n",
    "combOp = lambda #... \n",
    "\n",
    "y = x.aggregate(  ) #add correct parameters\n",
    "\n",
    "# these two lines should produce the same thing\n",
    "print(x.collect())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max, Min, Sum, Mean, Variance, Stdev\n",
    "\n",
    "Action / To Driver: Compute the respective function (maximum value, minimum value, sum, mean, variance, or standard deviation) from a numeric RDD\n",
    "\n",
    "![](http://i.imgur.com/HUCtib1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([2,4,1])\n",
    "print(x.collect())\n",
    "print(x.max(), x.min(), x.sum(), x.mean(), x.variance(), x.stdev())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountByKey\n",
    "\n",
    "Action / To Driver: Return a map of keys and counts of their occurrences in the RDD\n",
    "\n",
    "![](http://i.imgur.com/jvQTGv6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([('J', 'James'), ('F','Fred'), \n",
    "                    ('A','Anna'), ('J','John')])\n",
    "\n",
    "y = x.countByKey()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SaveAsTextFile\n",
    "\n",
    "Action / Distributed: Save the RDD to the filesystem indicated in the path\n",
    "\n",
    "![](http://i.imgur.com/Tb2Q9mG.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([2,4,1])\n",
    "x.saveAsTextFile(\"/tmp/training_demo\")\n",
    "\n",
    "y = sc.textFile(\"/tmp/training_demo\")\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "31-TransformBasic",
  "notebookId": 616564
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
