{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Washington Crime Lab (RDDs and DataFrames)\n",
    "\n",
    "In this lab, we'll explore some of the RDD concepts we've discussed. We'll be using a data set consisting of reported crimes in Washington D.C. from October 3, 2015 through October 2, 2016. This data comes from the [District of Columbia's Open Data Catalog](http://data.octo.dc.gov/). We'll use this data to explore some RDD transitions and actions.\n",
    "\n",
    "## Exercises and Solutions\n",
    "\n",
    "This notebook contains a number of exercises. Use the API docs for methods\n",
    "<a href=\"http://spark.apache.org/docs/1.6.1/api/scala/index.html#org.apache.spark.rdd.RDD\" target=\"_blank\">common to all RDDs</a>,\n",
    "plus the extra methods for\n",
    "<a href=\"http://spark.apache.org/docs/1.6.1/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions\" target=\"_blank\">pair RDDs</a>, to look up transformations and actions. If, at any point, you're struggling with the solution to an exercise, feel free to look in the **Solutions** notebook (in the same folder as this lab).\n",
    "\n",
    "## Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load the data\n",
    "\n",
    "The first step is to load the data. Run the following cell to create an RDD containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d8afe1d88264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_rdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/data/training/washington_crime_incidents_2013.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "base_rdd = sc.textFile(\"/data/training/washington_crime_incidents_2013.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question**: Does the RDD _actually_ contain the data right now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the data\n",
    "\n",
    "Let's take a look at some of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for line in base_rdd.take(10):\n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Okay, there's a header. We'll need to remove that. But, since the file will be split into partitions, we can't just drop the first item. Let's figure out another way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "no_header_rdd = base_rdd.filter(lambda line: \"REPORTDATETIME\" not in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for line in no_header_rdd.take(10):\n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Let's make things a little easier to handle, by converting the `noHeaderRDD` to an RDD containing Scala objects.\n",
    "\n",
    "**TO DO**\n",
    "\n",
    "* Split each line into its individual cells.\n",
    "* Map the RDD into another RDD of appropriate `CrimeData` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Replace the <FILL-IN> sections with appropriate code.\n",
    "\n",
    "# TAKE NOTE: We are deliberately only keeping the first five fields of\n",
    "# each line, since that's all we're using in this lab. There's no sense\n",
    "# in dragging around more data than we need.\n",
    "from collections import namedtuple\n",
    "from pprint import pprint\n",
    "\n",
    "CrimeData = namedtuple('CrimeData', ['ccn', 'report_time', 'shift', 'offense', 'method'])\n",
    "\n",
    "def map_line(line):\n",
    "  columns = <FILL-IN>\n",
    "  return <FILL-IN>\n",
    "\n",
    "data_rdd = no_header_rdd.map(map_line)\n",
    "pprint(data_rdd.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Next, group the data by type of crime (the \"OFFENSE\" column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Replace <FILL-IN> with the appropriate code.\n",
    "\n",
    "grouped_by_offense_rdd = data_rdd.groupBy(lambda data: <FILL-IN>)\n",
    "pprint(grouped_by_offense_rdd.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 3\n",
    "Next, create an RDD that counts the number of each offense. How many murders were there in the period covered by the data? How many assaults with a dangerous weapon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Replace <FILL-IN> with the appropriate code.\n",
    "\n",
    "offense_counts = <FILL-IN>\n",
    "for offense, count in <FILL-IN>:\n",
    "  print(\"{0:30s} {1:d}\".format(offense, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question\n",
    "\n",
    "Run the following cell. Can you explain what happened? Is `collectAsMap()` a _transformation_ or an _action_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grouped_by_offense_rdd.collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "How many partitions does the base RDD have? What about the `groupedByOffenseRDD` RDD? How can you find out?\n",
    "\n",
    "**Hint**: Check the [API documentation](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Replace <FILL-IN> with the appropriate code.\n",
    "print(base_rdd.<FILL-IN>)\n",
    "print(grouped_by_offense_rdd.<FILL-IN>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "Since we're continually playing around with this data, we might as well cache it, to speed things up.\n",
    "\n",
    "**Question**: Which RDD should you cache?\n",
    "\n",
    "1. `baseRDD`\n",
    "2. `noHeaderRDD`\n",
    "3. `dataRDD`\n",
    "4. None of them, because they're all still too big.\n",
    "5. It doesn't really matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Replace <FILL-IN> with the appropriate code.\n",
    "<FILL-IN>.cache().count() # Why am I calling count() here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 6\n",
    "\n",
    "Display the number of homicides by weapon (method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Replace <FILL-IN> with the appropriate code.\n",
    "result_rdd1 = data_rdd.<FILL-IN>\n",
    "print(result_rdd1.collect())\n",
    "\n",
    "# BONUS: Make the output look better, using a for loop or a list comprehension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 7\n",
    "\n",
    "During which police shift did the most crimes occur in the period covered by the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Replace <FILL-IN> with the appropriate code.\n",
    "\n",
    "# Hint: Start with the data_rdd\n",
    "print(data_rdd.<FILL-IN>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Let's Switch to DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Demonstration\n",
    "\n",
    "Let's plot murders by month. DataFrames are useful for this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To do this properly, we'll need to parse the dates. That will require knowing their format. A quick sampling of the data will help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_rdd.map(lambda item: item.report_time).take(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Okay. We can now parse the strings into actual `Date` objects.\n",
    "\n",
    "**NOTE:** The DataFrame API does _not_ support schemas with `Date` objects in them. We'll need to convert the resulting `Date` to a `java.sql.Timestamp`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we can create the DataFrame. We'll start with the `dataRDD`, since it's already cached. Note that we're using the built-in `unix_timestamp` function, which parses\n",
    "a string according to a Java [SimpleDateFormat](https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html) pattern, returning the number of seconds since\n",
    "the epoch (January 1, 1970 at midnight UTC), which we can then cast to a SQL timestamp type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "df0 = data_rdd.toDF()\n",
    "df = df0.select(unix_timestamp(df0['report_time'], 'M/dd/yyyy KK:mm:SS a').cast('timestamp').alias('report_time'),\n",
    "                df0['shift'],\n",
    "                df0['offense'],\n",
    "                df0['method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's use the built-in\n",
    "<a href=\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$@month(e:org.apache.spark.sql.Column):org.apache.spark.sql.Column\" target=\"_blank\"><tt>month</tt></a>\n",
    "function to extract the month. Note that the months are 0-indexed. Let's make the 1-indexed, since that makes more sense to us humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_with_month = df.select(df['*'], month(df['report_time']).alias('month'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "  df_with_month.filter(df_with_month['offense'] == 'HOMICIDE')\n",
    "               .select(df_with_month['month'], df_with_month['offense'])\n",
    "               .groupBy('month')\n",
    "               .count()\n",
    "               .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What about all crimes per month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_with_month.select(df_with_month['month']).groupBy('month').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 8\n",
    "\n",
    "Plot the frequency of crimes by hour of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Replace <FILL-IN> with your code.\n",
    "\n",
    "  <FILL-IN>.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "Washington-Crime_student",
  "notebookId": 800662
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
